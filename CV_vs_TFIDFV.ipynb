{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AIFq7QHcrz7D"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import re\n",
    "from urlextract import URLExtract\n",
    "import emojis\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adadelta,Adam,RMSprop\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('Snappfood - Sentiment Analysis.csv', on_bad_lines='skip', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
       "      <td>SAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
       "      <td>SAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>عالللی بود همه چه درست و به اندازه و کیفیت خوب...</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>عالی بود همه چه درست و به اندازه و کیفیت خوب، ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>شیرینی وانیلی فقط یک مدل بود</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label  label_id  \\\n",
       "0    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح    SAD       1.0   \n",
       "1  قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...  HAPPY       0.0   \n",
       "2  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...    SAD       1.0   \n",
       "3  عالللی بود همه چه درست و به اندازه و کیفیت خوب...  HAPPY       0.0   \n",
       "4                      شیرینی وانیلی فقط یک مدل بود.  HAPPY       0.0   \n",
       "\n",
       "                                             Cleaned  \n",
       "0    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح  \n",
       "1  قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...  \n",
       "2  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...  \n",
       "3  عالی بود همه چه درست و به اندازه و کیفیت خوب، ...  \n",
       "4                      شیرینی وانیلی فقط یک مدل بود   "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uhxQLjd7svuw"
   },
   "outputs": [],
   "source": [
    "def _multiple_replace(mapping, text):\n",
    "    pattern = \"|\".join(map(re.escape, mapping.keys()))\n",
    "    return re.sub(pattern, lambda m: mapping[m.group()], str(text))\n",
    "\n",
    "def convert_fa_numbers(input_str):\n",
    "    mapping = {\n",
    "        '۰': '0',\n",
    "        '۱': '1',\n",
    "        '۲': '2',\n",
    "        '۳': '3',\n",
    "        '۴': '4',\n",
    "        '۵': '5',\n",
    "        '۶': '6',\n",
    "        '۷': '7',\n",
    "        '۸': '8',\n",
    "        '۹': '9',\n",
    "        '.': '.',\n",
    "    }\n",
    "    return _multiple_replace(mapping, input_str)\n",
    "\n",
    "\n",
    "def convert_ar_characters(input_str):\n",
    "    \"\"\"\n",
    "    Converts Arabic chars to related Persian unicode char\n",
    "    :param input_str: String contains Arabic chars\n",
    "    :return: New str with converted arabic chars\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        'ك': 'ک',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی',\n",
    "        'ئ':'ی',\n",
    "        'إ':'ا',\n",
    "        'أ':'ا',\n",
    "        'ة':'ه',\n",
    "        'ؤ':'و'\n",
    "    }\n",
    "    return _multiple_replace(mapping, input_str)\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    extractor = URLExtract()\n",
    "    for url in extractor.gen_urls(text):\n",
    "        text = text.replace(url,'<URL>')\n",
    "    emj = emojis.get(text)\n",
    "    for i in emj:\n",
    "        if i in text:\n",
    "            text = text.replace(i,'<emoji>')\n",
    "    text = convert_fa_numbers(text)\n",
    "    text = convert_ar_characters(text)\n",
    "    # regex to detect and replace all smilies in the text with <smiley>\n",
    "    text = re.sub(r\"(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\)|:\\s?D|8-\\)|:\\s?\\||;\\s?\\)|:-\\*|:-\\||:-\\(|:\\s?P|:-P|:-p|:-b|:-O|:-o|:-0|:-\\@|:\\$|:-\\^|:-&|:-\\*|:-\\+|:-\\~|:-\\`|:-\\>|:-\\<|:-\\}|:-\\{|\\[:\\s?\\]|\\[:\\s?\\]|:\\s?\\]|:\\s?\\[|:\\s?\\}|:\\s?\\{)\",'<smiley>',text)\n",
    "    text = text.lower() # we lowercase here to prevent changes in the URLs and smilies\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[<>#.:()\"\\'!?؟،,@$%^&*_+\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'[\\s]{2,}', ' ', text)\n",
    "    text = re.sub(r'(\\w)\\1{2,}', r'\\1',text)\n",
    "    if re.search(r'[\\u0600-\\u06FF]', text):\n",
    "        return(text)\n",
    "    else:\n",
    "        return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PRXfgSJKum7t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 70000/70000 [37:40<00:00, 30.96it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus['Cleaned'] = corpus['comment'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
       "      <td>SAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
       "      <td>SAD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>عالللی بود همه چه درست و به اندازه و کیفیت خوب...</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>عالی بود همه چه درست و به اندازه و کیفیت خوب، ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>شیرینی وانیلی فقط یک مدل بود.</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>شیرینی وانیلی فقط یک مدل بود</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            comment  label  \\\n",
       "0        NaN    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح    SAD   \n",
       "1        NaN  قرار بود ۱ ساعته برسه ولی نیم ساعت زودتر از مو...  HAPPY   \n",
       "2        NaN  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...    SAD   \n",
       "3        NaN  عالللی بود همه چه درست و به اندازه و کیفیت خوب...  HAPPY   \n",
       "4        NaN                      شیرینی وانیلی فقط یک مدل بود.  HAPPY   \n",
       "\n",
       "   label_id                                            Cleaned  \n",
       "0       1.0    واقعا حیف وقت که بنویسم سرویس دهیتون شده افتضاح  \n",
       "1       0.0  قرار بود 1 ساعته برسه ولی نیم ساعت زودتر از مو...  \n",
       "2       1.0  قیمت این مدل اصلا با کیفیتش سازگاری نداره، فقط...  \n",
       "3       0.0  عالی بود همه چه درست و به اندازه و کیفیت خوب، ...  \n",
       "4       0.0                      شیرینی وانیلی فقط یک مدل بود   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "id": "B4TlV5TMYAAI",
    "outputId": "ff69b746-5b64-4813-caa3-a7e376758757"
   },
   "outputs": [],
   "source": [
    "corpus = corpus.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SK0xYDV3a6fu",
    "outputId": "cc808319-fb98-487f-d613-1971cf926921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69480 entries, 0 to 69999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   comment   69480 non-null  object \n",
      " 1   label     69480 non-null  object \n",
      " 2   label_id  69480 non-null  float64\n",
      " 3   Cleaned   69480 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('snappfood_comments_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NGfZZ3eaAhzQ"
   },
   "outputs": [],
   "source": [
    "# with open('stop words - Farsi.txt', 'r', encoding='utf-8') as f:\n",
    "#     stopwords = f.read().splitlines()\n",
    "\n",
    "# corpus['Cleaned_sw_rmvd'] = corpus['Cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dEMnhzO7lh3L"
   },
   "outputs": [],
   "source": [
    "# def text_normalizer(text):\n",
    "#   stemmer = Stemmer()\n",
    "#   text = stemmer.stem(text)\n",
    "\n",
    "#   normalizer = Normalizer()\n",
    "#   text = normalizer.normalize(text)\n",
    "\n",
    "#   return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1knHnQ_Zh2bz"
   },
   "outputs": [],
   "source": [
    "# corpus['Cleaned_normalized'] = corpus['Cleaned'].progress_apply(lambda x: text_normalizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "vLM1dIDosHBu",
    "outputId": "e867e5a9-3481-4379-dbb5-e7388fa03736"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X_count_vectorized = count_vectorizer.fit_transform(corpus.Cleaned).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "X98jIgq-7LlO"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2, max_features= 10000)\n",
    "X_tfidf_vectorized = vectorizer.fit_transform(corpus.Cleaned).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "axnht46GsMrE"
   },
   "outputs": [],
   "source": [
    "labels = corpus['label_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2nPE3riZsQq9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_count_vectorized, labels, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iM9HDF1g7kOd"
   },
   "outputs": [],
   "source": [
    "X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(X_tfidf_vectorized, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5PbE_h-uw3a3"
   },
   "outputs": [],
   "source": [
    "input_dim = X_tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55584, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "MznQEJNexd0T",
    "outputId": "4be72626-51bf-47a9-9a4c-71440477299c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ramin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\users\\ramin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\ramin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8488054116292458\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62mnZSEHUo0d",
    "outputId": "0e1091b5-53b8-4546-fa22-1ba5d72294d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ramin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "c:\\users\\ramin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\ramin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8645653425446171\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_tfidf_train, y_tfidf_train)\n",
    "tfidf_score = clf.score(X_tfidf_test, y_tfidf_test)\n",
    "print(\"Accuracy:\", tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Oe5GjQr_xe2G"
   },
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "batch_size = 32\n",
    "nb_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0WedYtwM0Cvl"
   },
   "outputs": [],
   "source": [
    "y_tfidf_train_cat = np_utils.to_categorical(y_tfidf_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "R8uq2mQ6xtTG"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1000,input_shape= (input_dim[1],)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "M-z2tvGS3hHd"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Au7_LegeyEc8",
    "outputId": "46388074-51e5-4c5a-918a-fa050b77d1a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ramin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1737/1737 - 131s - loss: 0.3614 - 131s/epoch - 75ms/step\n",
      "Epoch 2/10\n",
      "1737/1737 - 133s - loss: 0.2851 - 133s/epoch - 77ms/step\n",
      "Epoch 3/10\n",
      "1737/1737 - 127s - loss: 0.2203 - 127s/epoch - 73ms/step\n",
      "Epoch 4/10\n",
      "1737/1737 - 129s - loss: 0.1307 - 129s/epoch - 74ms/step\n",
      "Epoch 5/10\n",
      "1737/1737 - 131s - loss: 0.0721 - 131s/epoch - 75ms/step\n",
      "Epoch 6/10\n",
      "1737/1737 - 129s - loss: 0.0448 - 129s/epoch - 74ms/step\n",
      "Epoch 7/10\n",
      "1737/1737 - 131s - loss: 0.0325 - 131s/epoch - 75ms/step\n",
      "Epoch 8/10\n",
      "1737/1737 - 129s - loss: 0.0265 - 129s/epoch - 74ms/step\n",
      "Epoch 9/10\n",
      "1737/1737 - 130s - loss: 0.0208 - 130s/epoch - 75ms/step\n",
      "Epoch 10/10\n",
      "1737/1737 - 129s - loss: 0.0178 - 129s/epoch - 74ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266919a39d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tfidf_train, y_tfidf_train_cat, batch_size=batch_size, epochs=nb_epochs,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hsVo2k53yaB",
    "outputId": "655caf59-ca6c-4e21-cce2-375b9f52424e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435/435 [==============================] - 8s 19ms/step\n",
      "1737/1737 [==============================] - 34s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_tfidf_test)\n",
    "y_test_predclass = np.argmax(y_test_pred, axis=1)\n",
    "y_trian_pred = model.predict(X_tfidf_train)\n",
    "y_train_predclass = np.argmax(y_trian_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwavY-uA4Pks",
    "outputId": "929a071b-03ab-4380-f4d4-c6ec1df053bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nDeep Neural Network - Test accuracy: 83.97\n",
      "nDeep Neural Network - Train accuracy: 99.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print (\"nDeep Neural Network - Test accuracy:\",(round(accuracy_score(y_tfidf_test, y_test_predclass),4)*100))\n",
    "print (\"nDeep Neural Network - Train accuracy:\",(round(accuracy_score(y_tfidf_train, y_train_predclass),4)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "CX9xLlY_WBCI"
   },
   "outputs": [],
   "source": [
    "X_pred = vectorizer.transform([preprocess('دیگه از این رستوران سفارش نمیدم')]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoU2n0MNWbXW",
    "outputId": "e0512765-6eb8-4851-e974-543c4130c8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00547247, 0.9945275 ]], dtype=float32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
